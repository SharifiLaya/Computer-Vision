{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "To identify the plant seedlings species from 12 different species using a convolutional neural network",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP-OO_5cWiwJ"
      },
      "source": [
        "# **Project Description – Image classification using CNNs in Keras**\n",
        "**Data Description:**\n",
        "\n",
        "You are provided with a dataset of images of plant seedlings at various stages of grown. Each image has a filename that is its unique id. The dataset comprises 12 plant species. The goal of the project is to create a classifier capable of determining a plant's species from a photo.\n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "The dataset can be download from Olympus.\n",
        "\n",
        "The data file names are:\n",
        "\n",
        "\n",
        "*   images.npy\n",
        "*   Label.csv\n",
        "\n",
        "\n",
        "\n",
        "The original files are from Kaggle. Due to the large volume of data, the images were converted to images.npy file and the labels are also put into the Labels.csv. So that you can work on the data/project seamlessly without worrying about the high data volume.\n",
        "\n",
        "Link to the Kaggle project site:\n",
        "\n",
        " https://www.kaggle.com/c/plant-seedlings-classification/data?select=train\n",
        " \n",
        "**Context:**\n",
        "\n",
        "Can you differentiate a weed from a crop seedling?\n",
        "\n",
        "The ability to do so effectively can mean better crop yields and better stewardship of the environment.\n",
        "\n",
        "The Aarhus University Signal Processing group, in collaboration with University of Southern Denmark, has recently released a dataset containing images of unique plants belonging to 12 species at several growth stages\n",
        "\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "To implement the techniques learnt as a part of the course.\n",
        "\n",
        "**Learning Outcomes:**\n",
        "\n",
        "*   Pre-processing of image data.\n",
        "*   Visualization of images.\n",
        "*   Building CNN.\n",
        "*   Evaluate the Model.\n",
        "*   The motive of the project is to make the learners capable to handle images/image classification problems, during this process you should also be capable to handle real image files, not just limited to a numpy array of image pixels\n",
        "\n",
        "**Guide to solve the project seamlessly:**\n",
        "\n",
        "Here are the points which will help you to solve the problem efficiently:\n",
        "\n",
        " Read the problem statement carefully from start to end (including the note at the end). The highlighted part in the attached problem statement should not be missed.\n",
        "\n",
        " Download the dataset from the Olympus platform.\n",
        "\n",
        " Upload the \"images.npy\" and “Labels.csv” file to google drive.\n",
        "\n",
        " Then you can use the dataset path in the Google Colab notebook to do further steps related to project problem statement.\n",
        "\n",
        " You can set runtime type to “GPU” in Google Colab, so that the code will run faster as you will be using CNN to fit your model.\n",
        "\n",
        "**Steps and tasks:**\n",
        "1. Import the libraries, load dataset, print shape of data, visualize the images in dataset. (5 Marks)\n",
        "2. Data Pre-processing: (15 Marks)\n",
        "\n",
        "a. Normalization.\n",
        "\n",
        "b. Gaussian Blurring.\n",
        "\n",
        "c. Visualize data after pre-processing.\n",
        "3. Make data compatible: (10 Marks)\n",
        "\n",
        "a. Convert labels to one-hot-vectors.\n",
        "\n",
        "b. Print the label for y_train[0].\n",
        "\n",
        "c. Split the dataset into training, testing, and validation set.\n",
        "(Hint: First split images and labels into training and testing set with test_size = 0.3. Then further split test data into test and validation set with test_size = 0.5)\n",
        "\n",
        "d. Check the shape of data, Reshape data into shapes compatible with Keras models if it’s not already. If it’s already in the compatible shape, then comment in the notebook that it’s already in compatible shape.\n",
        "4. Building CNN: (15 Marks)\n",
        "\n",
        "a. Define layers.\n",
        "\n",
        "b. Set optimizer and loss function. (Use Adam optimizer and categorical crossentropy.)\n",
        "\n",
        "5. Fit and evaluate model and print confusion matrix. (10 Marks)\n",
        "6. Visualize predictions for x_test[2], x_test[3], x_test[33], x_test[36], x_test[59]. (5 Marks)\n",
        "\n",
        "**Note:**\n",
        "\n",
        "\n",
        "*   Download the train images from the Olympus Platform.\n",
        "*   Do not download the dataset from Kaggle, as:\n",
        "\n",
        "  *   The dataset is big.\n",
        "  *   The dataset has 2 files for train and test images, but the labels are only for the train file. Test file has no labels associated with it. So, when you want to know the accuracy of model on test images, there’s no way to measure it. That’s why the data provided to you on Olympus has only train images and their labels. For our purpose we use this for our training and testing and validation purpose\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsvb7A4KK-Qa"
      },
      "source": [
        "### Import the libraries, load dataset, print shape of data, visualize the images in dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9A-Zxy0W9Uf"
      },
      "source": [
        "# Import necessary modules.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from tensorflow.keras import datasets, models, layers, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import animation\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQWIOHoec8J6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftwWcLi9MyhY"
      },
      "source": [
        "**Read Images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5EfG0wOZkl-"
      },
      "source": [
        "project_path = '/content/drive/My Drive/CoLab-Project/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu8KgKx6ZuLU"
      },
      "source": [
        "\n",
        "lables = project_path + 'Labels.xls'\n",
        "img_file=project_path + 'images.npy'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PktRt0VxaTr8"
      },
      "source": [
        "\n",
        "# load the dataset\n",
        "lables = pd.read_csv(lables)\n",
        "img_array= np.load(img_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0i_EOSmCUKU"
      },
      "source": [
        "# img_array=np.load('/content/drive/My Drive/CoLab-Project/images.npy')\n",
        "# lables = pd.read_csv('/content/drive/My Drive/CoLab-Project/Labels.xls')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8GCWbkTM5u1"
      },
      "source": [
        "\n",
        "lables.Label.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ec8JtgdbD_t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LouIfblmR4bf"
      },
      "source": [
        "**Number of images in each class**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT2Kg3HRRdbL"
      },
      "source": [
        "lables.Label.value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnceBFT3_wx-"
      },
      "source": [
        "# import pandas as pd \n",
        "# Imag_Count = pd.DataFrame(lables.Label.value_counts().reset_index().values, columns=[\"Class\", \"AggregateClass\"])\n",
        "# Imag_Countindex =Imag_Count.sort_index(axis = 0, ascending=True)\n",
        "# Imag_Countindex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beypIOFLAQW-"
      },
      "source": [
        "ax = sns.FacetGrid(lables.Label, size=5, aspect=2)\n",
        "ax = sns.barplot(x=\"Class\", y=\"AggregateClass\", data=Imag_Countindex, palette=\"Blues_d\")\n",
        "ax.set_xticklabels(ax.get_xticklabels(),rotation=30);\n",
        "\n",
        "# Or using seaborn library\n",
        "# import seaborn as sns\n",
        "# fig, ax = plt.subplots(figsize=(22,7))\n",
        "# sns.countplot(lables['Label'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFDAUNgj63MO"
      },
      "source": [
        "**Print shape of data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBRoenQI6M_z"
      },
      "source": [
        "print(img_array.shape)\n",
        "print(lables.shape)\n",
        "# print(classes[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvDtHjtCb5Ut"
      },
      "source": [
        "**Insights:**\n",
        "\n",
        "There are total 4750 images.\n",
        "\n",
        "Size of each image is 128x128 pixels.\n",
        "\n",
        "Each image has three color channels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vND6LyqU5rj_"
      },
      "source": [
        "**Visualize the images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQLTK96hJ1n3"
      },
      "source": [
        "Itrate on all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5SWu2zFEYex"
      },
      "source": [
        "for i in range(0, 12 ):\n",
        "  image = img_array[i]\n",
        "  plt.imshow(image)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ2oHy-hCjPd"
      },
      "source": [
        "plt.imshow(img_array[8], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR-2wVPn7kX_"
      },
      "source": [
        "**Data Pre-processing:**\n",
        "*   Normalization\n",
        "*   Gaussian Blurring\n",
        "*   Visualize data after pre-processing\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IL-4XB4Bcc0v"
      },
      "source": [
        "**a. Normalization** \n",
        "When using Neural Networks, Normalization helps. (Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process.) As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUNdFirUcrbO"
      },
      "source": [
        "img_array[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zO36fzZ7jZL"
      },
      "source": [
        "img_array = img_array.astype('float32') # Conversion to float type from integer type.\n",
        "img_array /= 255.0 # Division by 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpjOo97Bc5eC"
      },
      "source": [
        "**b. Gaussian Blurring**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJISpW3s8mFM"
      },
      "source": [
        "Gaussian1 = cv2.GaussianBlur(img_array[8], (5, 5), 0)\n",
        "Gaussian2 = cv2.GaussianBlur(img_array[8], (15, 15), 0)\n",
        "print('Original Image:\\n')\n",
        "plt.imshow(img_array[8])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT34YW_OdKot"
      },
      "source": [
        "\n",
        "**c. Visualize data after pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MUwkq8RUEd5"
      },
      "source": [
        "print('\\n Output after first gaussian blurring: \\n')\n",
        "# cv2_imshow(Gaussian1)\n",
        "plt.imshow(Gaussian1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI00NdQU8mUj"
      },
      "source": [
        "print('\\n Output after second gaussian blurring: \\n')\n",
        "# cv2_imshow(Gaussian2)\n",
        "plt.imshow(Gaussian2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuX365ggVAf2"
      },
      "source": [
        "### Making data compatible\n",
        "\n",
        "a. Convert labels to one-hot-vectors. \n",
        "\n",
        "b. Print the label for y_train[0]. \n",
        "\n",
        "c. Split the dataset into training, testing, and validation set. (Hint: First split images and labels into training and testing set with test_size = 0.3. Then further split test data into test and validation set with test_size = 0.5) \n",
        "\n",
        "d. Check the shape of data, Reshape data into shapes compatible with Keras models if it’s not already. If it’s already in the compatible shape, then comment in the notebook that it’s already in compatible shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX47RU1pdgtQ"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raWeUfWBF-lQ"
      },
      "source": [
        "**a. Convert labels to one-hot-vectors.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfqCQ8E2eK1i"
      },
      "source": [
        "# creating initial dataframe\n",
        "label_name = ('Small-flowered Cranesbill', 'Fat Hen', 'Shepherds Purse',\n",
        "       'Common wheat', 'Common Chickweed', 'Charlock', 'Cleavers',\n",
        "       'Scentless Mayweed', 'Sugar beet', 'Maize', 'Black-grass',\n",
        "       'Loose Silky-bent')\n",
        "labels = pd.DataFrame(label_name, columns=['label_name'])\n",
        "# converting type of columns to 'category'\n",
        "labels['label_name'] = labels['label_name'].astype('category')\n",
        "# Assigning numerical values and storing in another column\n",
        "labels['label'] = labels['label_name'].cat.codes\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpxcB7zFfVms"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "#creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "lables = labelencoder.fit_transform(lables);\n",
        "lables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NovvUCnyJXBf"
      },
      "source": [
        "# Convert labels to one hot vectors.\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "enc = LabelBinarizer()\n",
        "y = enc.fit_transform(lables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL2UGwhMGDid"
      },
      "source": [
        "**b. Print the label for y_train[0]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUAnJVBnn_WK"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O7qYQYCgvpE"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Paq1t0Z4ownB"
      },
      "source": [
        "**c. Spliting data into training and testing set**\n",
        "\n",
        "Split the dataset into training, testing, and validation set.\n",
        "\n",
        "(Hint: First split images and labels into training and testing set with test_size = 0.3. Then further split test data into test and validation set with test_size = 0.5)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMKb_mNoyZo"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(img_array, y, test_size=0.3, random_state=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62lrRWQ5Vlde"
      },
      "source": [
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxJtPMWkWUK1"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sFa-UNTpFK9"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKZqadtb0X2l"
      },
      "source": [
        "**Create validarion set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4RGlsGdw6CB"
      },
      "source": [
        "random_seed = 2\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_test, X_val, y_test, Y_val = train_test_split(X_test,y_test, test_size = 0.5, random_state=random_seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "654uUASs0oTl"
      },
      "source": [
        "print(X_test.shape)\n",
        "print(X_val.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf4Mx2_OTJli"
      },
      "source": [
        " \n",
        "**d. Check the shape of data, Reshape data into shapes compatible with Keras models if it’s not already. If it’s already in the compatible shape, then comment in the notebook that it’s already in compatible shape.**\n",
        "\n",
        "In Keras, the input layer itself is not a layer, but a tensor. It's the starting tensor you send to the first hidden layer. This tensor must have the same shape as our training data. Example: if you have 30 images of 50x50 pixels in RGB (3 channels), the shape of your input data is (30,50,50,3) ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3au4Kz-hJJR"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(Y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4duTWl8Kb4e8"
      },
      "source": [
        "We need to update input valume of the original size (larger dimensions) to smaller dimention to be compatible with keras size of ( 128 x 128x 3) , how ever our inpt data shape is already in size of 128 x 128 and compatible with our keras model \n",
        "\n",
        "X_train.shape : \n",
        "(3325, 128, 128, 3)\n",
        "\n",
        "reference : https://www.pyimagesearch.com/2019/06/24/change-input-shape-dimensions-for-fine-tuning-with-keras/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAI6092nWyJg"
      },
      "source": [
        "img = cv2.resize(X_train.shape[0],(32,32),3)\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvvhT7sl1LXj"
      },
      "source": [
        "### Building CNN MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGQI3PmFfpB_"
      },
      "source": [
        "**Conv2D:**\n",
        "Keras Conv2D is a 2D Convolution Layer, this layer creates a convolution kernel that is wind with layers input which helps produce a tensor of outputs.\n",
        "\n",
        "**Activation('relu'):**\n",
        "'relu' stands for Rectified linear unit. It is the most widely used activation function. Chiefly implemented in hidden layers of Neural network.\n",
        "ReLu is less computationally expensive than tanh and sigmoid because it involves simpler mathematical operations. At a time only a few neurons are activated making the network sparse making it efficient and easy for computation.\n",
        "\n",
        "**MaxPooling2D:**\n",
        "The objective MaxPooling Layer is to down-sample an input representation.\n",
        "This is done to in part to help over-fitting by providing an abstracted form of the representation. As well, it reduces the computational cost by reducing the number of parameters to learn.\n",
        "\n",
        "**Dropout:**\n",
        "Dropout is a technique used to improve over-fit on neural networks.\n",
        "Basically during training half of neurons on a particular layer will be deactivated. This improve generalization.\n",
        "Normally some deep learning models use Dropout on the fully connected layers, but is also possible to use dropout after the max-pooling layers, creating some kind of image noise augmentation.\n",
        "\n",
        "**Dense:**\n",
        "Dense layer implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
        "\n",
        "**Softmax:**\n",
        "The softmax function is also a type of sigmoid function but is handy when we are trying to handle classification problems.\n",
        "Usually used when trying to handle multiple classes. The softmax function would squeeze the outputs for each class between 0 and 1 and would also divide by the sum of the outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1I4eJji2x5J"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalMaxPooling2D\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Set the CNN model \n",
        "\n",
        "batch_size = None\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu', batch_input_shape = (batch_size,256, 256, 3)))\n",
        "model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'same', activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(GlobalMaxPooling2D())\n",
        "model.add(Dense(256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(12, activation = \"softmax\"))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH83klEVg7A_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77bJHUSsd3v5"
      },
      "source": [
        "**Setting optimizer and loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC2WhBLD4HYF"
      },
      "source": [
        "# initiate Adam optimizer\n",
        "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "# opt = Adam(lr=0.001)\n",
        "# optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzdLweP0hGyO"
      },
      "source": [
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYsn0RpqnTde"
      },
      "source": [
        "Adding **Early stopping callback** to the fit function is going to stop the training, if the val_loss is not going to change even '0.001' for more than 10 continous epochs\n",
        "\n",
        "Adding **Model Checkpoint callback** to the fit function is going to save the weights whenever val_loss achieves a new low value. Hence saving the best weights occurred during training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvmVqJNhrMiy"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10)\n",
        "\n",
        "model_checkpoint =  ModelCheckpoint('cifar_cnn_checkpoint_{epoch:02d}_loss{val_loss:.4f}.h5',\n",
        "                                                           monitor='val_loss',\n",
        "                                                           verbose=1,\n",
        "                                                           save_best_only=True,\n",
        "                                                           save_weights_only=True,\n",
        "                                                           mode='auto',\n",
        "                                                           period=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7QJ16lN3be3"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs = 50, validation_data = (X_val,Y_val),batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h40TCAx_4bcN"
      },
      "source": [
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0, batch_size = 38)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3bXvWyVi3eO"
      },
      "source": [
        "results = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJzKXxHmkwq0"
      },
      "source": [
        "print(model.metrics_names)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bc4Zs6_qtqW"
      },
      "source": [
        "### Fit and evaluate model and print confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZVr-ymMoD5F"
      },
      "source": [
        "\n",
        "# plot training history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH96azdOrEkD"
      },
      "source": [
        "\n",
        "fig, ax = plt.subplots(2,1 , figsize=(22,7))\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ9w92vxqEML"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8E9dDdmqHnO"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
        "\n",
        "import itertools\n",
        "plt.subplots(figsize=(22,7)) #set the size of the plot \n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "\n",
        "# Predict the values from the validation dataset\n",
        "Y_pred = model.predict(X_val)\n",
        "# Convert predictions classes to one hot vectors \n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "# Convert validation observations to one hot vectors\n",
        "Y_true = np.argmax(Y_val,axis = 1) \n",
        "# compute the confusion matrix\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "# plot the confusion matrix\n",
        "plot_confusion_matrix(confusion_mtx, classes = range(12))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8upG9-h4fir"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, auc\n",
        "CM=confusion_matrix(Y_true, Y_pred_classes)\n",
        "CM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uodt2qHelafc"
      },
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "cr=classification_report(Y_true, Y_pred_classes)\n",
        "print(cr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "117QZHwzqQRX"
      },
      "source": [
        "Predicted_classes = model.predict_classes(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hUXViVutq0k"
      },
      "source": [
        "wrong_preds = X_test[Predicted_classes != np.argmax(y_test)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNL4Va9ottFn"
      },
      "source": [
        "\n",
        "set(Predicted_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4mAiwx0riO0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6E0NfUBqQpQ"
      },
      "source": [
        "### Visualize predictions for x_test[2], x_test[3], x_test[33], x_test[36], x_test[59]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9Rvsr_dLFNA"
      },
      "source": [
        "enc.inverse_transform(np.array([y_test]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Husn6UstKNxe"
      },
      "source": [
        "plt.imshow(X_test[2])\n",
        "print(\"Actual class: {}\".format(enc.inverse_transform(np.array([y_test[2]]))))\n",
        "print(\"Predicted class: {}\".format(enc.inverse_transform(np.array([Y_pred[2]]))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0RRPwkmfPkY"
      },
      "source": [
        "# Predicted_classes = model.predict_classes(X_test)\n",
        "# pred = model.predict_classes(np.array([wrong_preds[i]]))[0]\n",
        "# act = np.argmax(y_test[i])\n",
        "# print(\"Predicted class: {}\".format(enc.classes_[pred]))\n",
        "# print(\"Actual class: {}\".format(enc.classes_[act]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEx0KrJKQbi"
      },
      "source": [
        "plt.imshow(X_test[3])\n",
        "print(\"Actual class: {}\".format(enc.inverse_transform(np.array([y_test[3]]))))\n",
        "print(\"Predicted class: {}\".format(enc.inverse_transform(np.array([Y_pred[3]]))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aef6PQGcKQjV"
      },
      "source": [
        "plt.imshow(X_test[33])\n",
        "print(\"Actual class: {}\".format(enc.inverse_transform(np.array([y_test[33]]))))\n",
        "print(\"Predicted class: {}\".format(enc.inverse_transform(np.array([Y_pred[33]]))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAsSXt2CKQqI"
      },
      "source": [
        "plt.imshow(X_test[36])\n",
        "print(\"Actual class: {}\".format(enc.inverse_transform(np.array([y_test[36]]))))\n",
        "print(\"Predicted class: {}\".format(enc.inverse_transform(np.array([Y_pred[36]]))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb8VpVPnKQxe"
      },
      "source": [
        "plt.imshow(X_test[59])\n",
        "print(\"Actual class: {}\".format(enc.inverse_transform(np.array([y_test[59]]))))\n",
        "print(\"Predicted class: {}\".format(enc.inverse_transform(np.array([Y_pred[59]]))))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoDhAveyKeQU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}